{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/latent-flow-model/blob/main/latent_flow_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup"
      ],
      "metadata": {
        "id": "QOiDHI7taUKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Pm-Fw6jn4A",
        "outputId": "f7658853-1090-4789-d1f9-617edb166c54",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 5, 6])\n"
          ]
        }
      ],
      "source": [
        "# @title mha me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def zero_module(module):\n",
        "    \"\"\"Zero out the parameters of a module and return it.\"\"\"\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads=None, d_head=8, cond_dim=None, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_head = d_head\n",
        "        self.n_heads = d_model // d_head\n",
        "        # self.d_head = d_model // n_heads\n",
        "        self.cond_dim = cond_dim\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.kv = nn.Linear(cond_dim or d_model, 2*d_model, bias=False)\n",
        "        # self.k = nn.Sequential(nn.Dropout(dropout), nn.Linear(cond_dim, d_model, bias=False))\n",
        "        # self.lin = nn.Linear(d_model, d_model)\n",
        "        self.lin = zero_module(nn.Linear(d_model, d_model))\n",
        "        self.drop = nn.Dropout(dropout) # indp before q,k,v; after linout\n",
        "        self.scale = self.d_head ** -.5\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [batch, T, d_model]=[batch, h*w, c], [batch, num_tok, cond_dim], [batch,T]\n",
        "        batch = x.shape[0]\n",
        "        if self.cond_dim==None: cond=x # is self attn\n",
        "        Q = self.q(x).view(batch, -1, self.n_heads, self.d_head).transpose(1, 2) # [batch, T, d_model] -> [batch, n_heads, T, d_head]\n",
        "        # K = self.k(x).view(batch, -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        K, V = self.kv(cond).view(batch, -1, self.n_heads, 2*self.d_head).transpose(1, 2).chunk(2, dim=-1) # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # linear attention # Softmax(Q) @ (Softmax(K).T @ V)\n",
        "        if mask != None:\n",
        "            mask = mask[:, None, :, None] # [batch,T] -> [batch,1,T,1]\n",
        "            K, V = K.masked_fill(mask, -torch.finfo(x.dtype).max), V.masked_fill(mask, -torch.finfo(x.dtype).max)\n",
        "        Q, K = Q.softmax(dim=-1)*self.scale, K.softmax(dim=-2)\n",
        "        context = K.transpose(-2,-1) @ V # [batch, n_heads, d_head, d_head]\n",
        "        out = Q @ context # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # # (quadratic) attention # Softmax(Q @ K.T) @ V\n",
        "        # attn = Q @ K.transpose(-2,-1) * self.scale # [batch, n_heads, T] # [batch, n_heads, T, T/num_tok]\n",
        "        # if mask != None: attn = attn.masked_fill(mask[:, None, :, None], -torch.finfo(attn.dtype).max) # [batch,T]->[batch,1,T,1]\n",
        "        # attention = torch.softmax(attn, dim=-1)\n",
        "        # out = self.drop(attention) @ V # [batch, n_heads, T, d_head]\n",
        "\n",
        "        out = out.transpose(1, 2).flatten(2)\n",
        "        return self.lin(out) # [batch, T, d_model]\n",
        "\n",
        "# if self, dont pass cond_dim in init, dont pass cond in fwd\n",
        "# Softmax(Q @ K.T) @ V ~ Softmax(Q) @ Softmax(K).T @ V\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model, d_head, cond_dim=None, ff_dim=None, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.norm1 = nn.RMSNorm(d_model) # LayerNorm RMSNorm\n",
        "        self.norm2 = nn.RMSNorm(d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.cond_dim = cond_dim\n",
        "        self.self = MultiHeadAttention(d_model, d_head=d_head, dropout=0)\n",
        "        self.cross = MultiHeadAttention(d_model, d_head=d_head, cond_dim=cond_dim, dropout=0)\n",
        "        act = nn.ReLU()\n",
        "        if ff_dim==None: ff_dim=d_model*4\n",
        "        self.ff = nn.Sequential(\n",
        "            # nn.RMSNorm(d_model), nn.Linear(d_model, ff_dim), nn.ReLU(), # ReLU GELU\n",
        "            # nn.RMSNorm(d_model), nn.Dropout(dropout), nn.Linear(ff_dim, d_model)\n",
        "            nn.RMSNorm(d_model), act, nn.Linear(d_model, ff_dim),\n",
        "            nn.RMSNorm(ff_dim), act, nn.Linear(ff_dim, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [b,c,h,w], [batch, num_tok, cond_dim], [batch,T]\n",
        "        bchw = x.shape\n",
        "        x = x.flatten(2).transpose(1,2) # [b,h*w,c]\n",
        "        if self.cond_dim==None: cond=None # is self attn\n",
        "        # x = self.norm1(x + self.drop(self.cross_attn(x, cond)))\n",
        "        # x = self.norm2(x + self.drop(self.ff(x)))\n",
        "        x = x + self.self(self.norm1(x))\n",
        "        x = x + self.cross(self.norm2(x), cond, mask)\n",
        "        x = x + self.ff(x)\n",
        "        return x.transpose(1,2).reshape(*bchw)\n",
        "\n",
        "\n",
        "d_model=8\n",
        "d_head=4\n",
        "batch=4\n",
        "h,w=5,6\n",
        "x=torch.rand(batch,d_model,h,w)\n",
        "cond_dim=10\n",
        "cross = AttentionBlock(d_model=d_model, d_head=d_head,cond_dim=cond_dim)\n",
        "num_tok=1\n",
        "cond=torch.rand(batch,num_tok,cond_dim)\n",
        "mask=torch.rand(batch,h*w)>0.5\n",
        "out = cross(x, cond)\n",
        "print(out.shape)\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j9wUA7Vk0Y03"
      },
      "outputs": [],
      "source": [
        "# @title RotEmb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class RotEmb(nn.Module): # Rotary Positional Embeddings\n",
        "    def __init__(self, dim, top=torch.pi, base=10000):\n",
        "        super().__init__()\n",
        "        self.theta = top / (base ** (torch.arange(0, dim, step=2, device=device) / dim))\n",
        "\n",
        "    def forward(self, pos): # [batch] in [0,1]\n",
        "        angles = (pos.unsqueeze(-1) * self.theta).unsqueeze(-1) # [seq_len, 1] * [dim // 2] -> [seq_len, dim // 2, 1]\n",
        "        rot_emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1) # [seq_len, dim // 2, 2]\n",
        "        return rot_emb.flatten(-2) # [seq_len, dim]\n",
        "\n",
        "# class LearnedSinusoidalPosEmb(nn.Module):\n",
        "#     \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n",
        "#     def __init__(self, dim):\n",
        "#         super().__init__()\n",
        "#         half_dim = dim // 2\n",
        "#         self.weights = nn.Parameter(torch.randn(1, half_dim))\n",
        "\n",
        "#     def forward(self, x): # [b]\n",
        "#         x = x.unsqueeze(-1)\n",
        "#         freqs = x * self.weights * 2 * math.pi # [b, 1] * [1, half_dim] = [b, half_dim]\n",
        "#         fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1) # [b, dim]\n",
        "#         fouriered = torch.cat((x, fouriered), dim = -1) # [b, 1+dim]\n",
        "#         return fouriered\n",
        "\n",
        "# rotemb = RotEmb(10)\n",
        "# seq_len=10\n",
        "# pos = torch.linspace(0,1,seq_len).to(device)#.unsqueeze(-1)\n",
        "# rot_emb = rotemb(pos)\n",
        "# print(rot_emb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CrossEmbedLayer PixelShuffleConv\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class CrossEmbedLayer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_sizes, stride=1):\n",
        "        super().__init__()\n",
        "        kernel_sizes = sorted(kernel_sizes)\n",
        "\n",
        "        r=2\n",
        "        balls = out_ch//r**2\n",
        "        mult = [1/(1.6**i) for i in range(len(kernel_sizes))]\n",
        "        mul = balls/sum(mult)\n",
        "        mult = [m*mul for m in mult]\n",
        "        dim_scales = [0]*len(kernel_sizes)\n",
        "        for i in range(balls):\n",
        "            ind = mult.index(max(mult))\n",
        "            dim_scales[ind] += 1\n",
        "            mult[ind] -= 1\n",
        "        dim_scales = [d*r**2 for d in dim_scales]\n",
        "        if 0 in dim_scales: print('dim_scales',dim_scales)\n",
        "        # 1/2 + 1/4 + 1/8 + ... + 1/2^num_kernels + 1/2^num_kernels of out_ch; smaller kernel allocated more channels\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_ch, dim_scale, kernel, stride=stride, padding=(kernel-stride)//2) for kernel, dim_scale in zip(kernel_sizes, dim_scales)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # return torch.cat([conv(x) for conv in self.convs], dim = 1)\n",
        "        out = torch.cat([conv(x) for conv in self.convs], dim = 1)\n",
        "        b,c,h,w = out.shape\n",
        "        out = out.reshape(b, -1, 4, h, w).transpose(1,2).reshape(b, c, h, w)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PixelShuffleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch = None, kernel_size=3, r=2):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch = in_ch\n",
        "        self.in_ch, self.out_ch, self.r = in_ch, out_ch, r\n",
        "        r = max(r, int(1/r))\n",
        "        if self.r>1: self.net = nn.Sequential(nn.Conv2d(in_ch, out_ch * r**2, kernel_size, 1, padding=kernel_size//2), nn.PixelShuffle(r)) # PixelShuffle: [b,c*r^2,h,w] -> [b,c,h*r,w*r] # upscale by upscale factor r # https://arxiv.org/pdf/1609.05158v2\n",
        "        elif self.r<1: self.net = nn.Sequential(nn.PixelUnshuffle(r), nn.Conv2d(in_ch * r**2, out_ch, kernel_size, 1, padding=kernel_size//2)) # PixelUnshuffle: [b,c,h*r,w*r] -> [b,c*r^2,h,w]\n",
        "        self.net.apply(self.init_conv_)\n",
        "\n",
        "    def init_conv_(self, conv):\n",
        "        if isinstance(conv, nn.Conv2d):\n",
        "            o, i, h, w = conv.weight.shape\n",
        "            conv_weight = torch.empty(self.out_ch, self.in_ch, h, w)\n",
        "            nn.init.kaiming_uniform_(conv_weight)\n",
        "            # print(conv.weight.shape, conv_weight.shape,max(self.r, int(1/self.r)), (0 if self.r>1 else 1))\n",
        "            conv.weight.data.copy_(conv_weight.repeat_interleave(max(self.r, int(1/self.r))**2, dim=(0 if self.r>1 else 1)))\n",
        "            nn.init.zeros_(conv.bias.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# d=PixelShuffleConv(3, 16, 7, r=1/2)\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model = PixelShuffleConv(in_ch=3, r=2).to(device)\n",
        "# print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 16x16 conv 17651 ; pixel(3)(3)  ; (1)(1)  ; (3,7,15)(3,7)  ; (3,5,7)(3,5) 42706 ; 7,5 70226\n",
        "# input = torch.rand((4,3,64,64), device=device)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n",
        "\n",
        "# model = PixelShuffleConv(in_ch=3, r=1/2).to(device)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r-cYioQer02v",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title unet me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# torch.set_default_dtype(torch.float16)\n",
        "\n",
        "import inspect\n",
        "class Seq(nn.Sequential):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "        for layer in self:\n",
        "            params = inspect.signature(layer.forward).parameters.keys()\n",
        "            layer._fwdparams = ','.join(params)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        for layer in self:\n",
        "            args = [x]\n",
        "            if 'emb' in layer._fwdparams: args.append(emb)\n",
        "            if 'cond' in layer._fwdparams: args.append(cond)\n",
        "            x = layer(*args)\n",
        "        return x\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None, emb_dim=None, drop=0.):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch=in_ch\n",
        "        act = nn.SiLU() #\n",
        "        self.block1 = nn.Sequential(nn.BatchNorm2d(in_ch), act, nn.Conv2d(in_ch, out_ch, 3, padding=1))\n",
        "        self.block2 = Seq(nn.BatchNorm2d(out_ch), scale_shift(out_ch, emb_dim) if emb_dim != None else nn.Identity(), act, nn.Conv2d(out_ch, out_ch, 3, padding=1))\n",
        "        # self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "        self.res_conv = zero_module(nn.Conv2d(in_ch, out_ch, 1)) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, emb=None): # [b,c,h,w], [batch, emb_dim]\n",
        "        h = self.block1(x)\n",
        "        h = self.block2(h, emb)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class scale_shift(nn.Module): # FiLM\n",
        "    def __init__(self, x_dim, t_dim):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(nn.SiLU(), nn.Linear(t_dim, x_dim*2),)\n",
        "\n",
        "    def forward(self, x, emb): # [b,c,h,w], [b,emb_dim]\n",
        "        scale, shift = self.time_mlp(emb)[..., None, None].chunk(2, dim=1) # [b,t_dim]->[b,2*x_dim,1,1]->[b,x_dim,1,1]\n",
        "        return x * (scale + 1) + shift\n",
        "\n",
        "class levelBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, emb_dim, cond_dim, n_head=None, d_head=8, updown=False, r=2):\n",
        "        super().__init__()\n",
        "        if updown=='down': in_ch = in_ch*r**2\n",
        "        elif updown=='up': out_ch = out_ch*r**2\n",
        "        if n_head==None: n_head = out_ch // d_head\n",
        "        layers = [\n",
        "            nn.PixelUnshuffle(r) if updown=='down' else nn.Identity(),\n",
        "            ResBlock(in_ch, out_ch, emb_dim=emb_dim),\n",
        "            AttentionBlock(out_ch, d_head, cond_dim),\n",
        "            nn.PixelShuffle(r) if updown=='up' else nn.Identity(),\n",
        "            ]\n",
        "        self.seq = Seq(*layers)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        return self.seq(x, emb, cond)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, d_model=16, out_ch=None, cond_dim=16, depth=4, num_res_blocks=1, n_head=-1, d_head=4):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.d_model = d_model # base channel count for the model\n",
        "        out_ch = out_ch or in_ch\n",
        "        n_head = d_model // d_head\n",
        "\n",
        "        self.rotemb = RotEmb(d_model)\n",
        "        emb_dim = d_model# * 4\n",
        "        self.time_emb = nn.Sequential(nn.Linear(d_model, emb_dim), nn.SiLU(), nn.Linear(emb_dim, emb_dim))\n",
        "\n",
        "        self.in_block = nn.Sequential(nn.Conv2d(in_ch, d_model, 3, padding=1))\n",
        "        # self.init_conv = CrossEmbedLayer(in_ch, dim_out=d_model, kernel_sizes=(3, 7, 15), stride=1) #if init_cross_embed else nn.Conv2d(in_ch, d_model, 7, padding = 7//2)\n",
        "\n",
        "        mult = [1,2,3,4] # [1,2,3,4] [1,2,2,2]\n",
        "        ch_list = [d_model * m for m in mult[:depth+1]] # [128, 256, 384, 512]\n",
        "\n",
        "        self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], emb_dim, cond_dim, updown=None if i==0 else 'down') for i in range(depth)])\n",
        "        # self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], emb_dim, cond_dim, updown='down') for i in range(depth)])\n",
        "\n",
        "        ch = ch_list[-1]*2**2 # 512\n",
        "        self.middle_block = Seq(\n",
        "            nn.PixelUnshuffle(2), ResBlock(ch, ch, emb_dim),\n",
        "            AttentionBlock(ch, d_head, cond_dim),\n",
        "            ResBlock(ch, ch, emb_dim), nn.PixelShuffle(2),\n",
        "        )\n",
        "        self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], emb_dim, cond_dim, updown=None if i==0 else 'up') for i in reversed(range(depth))])\n",
        "        # self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], emb_dim, cond_dim, updown='up') for i in reversed(range(depth))])\n",
        "\n",
        "        # self.out_block = nn.Sequential(nn.BatchNorm2d(d_model), nn.SiLU(), nn.Conv2d(d_model, out_ch, 3, padding=1)) # zero\n",
        "        self.out_block = nn.Sequential(nn.BatchNorm2d(d_model), nn.SiLU(), zero_module(nn.Conv2d(d_model, out_ch, 3, padding=1))) # zero\n",
        "        # self.final_conv = nn.Conv2d(d_model, self.out_ch, 3, padding = 3//2) # lucid; or prepend final res block\n",
        "\n",
        "    def forward(self, x, t=None, cond=None): # [N, c,h,w], [N], [N, cond_dim]\n",
        "        t_emb = self.rotemb(t)\n",
        "        emb = self.time_emb(t_emb) #+ self.label_emb(y) # class conditioning nn.Embedding(num_classes, emb_dim)\n",
        "\n",
        "        blocks = []\n",
        "        x = self.in_block(x)\n",
        "        for i, down in enumerate(self.down_list):\n",
        "            x = down(x, emb, cond)\n",
        "            blocks.append(x)\n",
        "        x = self.middle_block(x, emb, cond)\n",
        "        for i, up in enumerate(self.up_list):\n",
        "            # print(\"unet fwd\", x.shape,blocks[-i-1].shape)\n",
        "            x = torch.cat([x, blocks[-i-1]*2**.5], dim=1) # scale residuals by 1/sqrt2\n",
        "            x = up(x, emb, cond) # x = up(x, blocks[-i - 1])\n",
        "        return self.out_block(x)\n",
        "\n",
        "\n",
        "\n",
        "# 64,64 -vae-> 16,16 -unet->\n",
        "batch = 4\n",
        "cond_dim=10\n",
        "model = UNet(in_ch=1, d_model=16, cond_dim=cond_dim, depth=3).to(device)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# print(model)\n",
        "\n",
        "# x=torch.rand((batch,3,16,16),device=device)\n",
        "x=torch.rand((batch,1,16,16),device=device)\n",
        "t = torch.rand((batch,), device=device) # in [0,1] [N]\n",
        "cond=torch.rand((batch,cond_dim),device=device)\n",
        "out = model(x, t, cond)\n",
        "print(out.shape)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3) # 1e-3 3e-3\n",
        "# cond_emb = nn.Embedding(10, cond_dim).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4R77KQvNgj4",
        "outputId": "7115eee4-5b2b-4d1e-8575-844a15364faf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5312817\n",
            "torch.Size([4, 1, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XwpnHW4wn9S1"
      },
      "outputs": [],
      "source": [
        "# @title data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),) # do not normalise! want img in [0,1)\n",
        "batch_size = 128 # 64 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# dataiter = iter(train_data)\n",
        "# x,y = next(dataiter)\n",
        "# print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf2bipgghY7O",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c143d3-aa69-4376-859a-2d48520c9a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/distributions/distribution.py:56: UserWarning: <class '__main__.LogitNormal'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title LogitNormal\n",
        "import torch\n",
        "import torch.distributions as dist\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LogitNormal(dist.Distribution):\n",
        "    def __init__(self, mu=0, std=.5):\n",
        "        super().__init__()\n",
        "        self.mu, self.std = mu, std\n",
        "        self._normal = dist.Normal(mu, std) # https://pytorch.org/docs/stable/distributions.html#normal\n",
        "\n",
        "    def rsample(self, sample_shape=torch.Size()):\n",
        "        eps = self._normal.rsample(sample_shape)\n",
        "        return torch.sigmoid(eps) # https://en.wikipedia.org/wiki/Logit-normal_distribution\n",
        "\n",
        "logit_normal = LogitNormal()\n",
        "# samples = logit_normal.rsample((10,))\n",
        "# print(samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title sampling timestep\n",
        "# def InverseSigmoid(x): return torch.log(x/(1-x))\n",
        "# def Normal(x, mu=0, std=.5): return torch.exp(-.5*((x-mu)/std)**2)/(std*(2*torch.pi)**2)\n",
        "# def LogitNormalPDF(x, mu=0, std=.5): return torch.nan_to_num(Normal(logit(x), mu, std) * 1/(x*(1-x)))\n",
        "\n",
        "# def invlogit(x): return torch.exp(x)/(1+torch.exp(x))\n",
        "# def InvLogitNormalCDF(x, mu=0, std=.5):\n",
        "#     cdf = invlogit(torch.erfinv(2*x-1)*(2**.5*std)+mu)\n",
        "#     cdf[x==1.] = 1 # lol, replace nan with 1 when x=1\n",
        "#     return cdf\n",
        "\n",
        "def logit(x): return torch.log(x/(1-x)) # x in (0,1)\n",
        "def LogitNormalCDF(x, mu=0, std=.5): # _/- for std<1.8; /-/ for std>1.8\n",
        "    cdf = 1/2 * (1 + torch.erf((logit(x)-mu)/(2**.5*std)))\n",
        "    return cdf\n",
        "\n",
        "def Cosine(x): return .5*(-torch.cos(torch.pi*x)+1) # _/-\n",
        "def Polynomial(x): return -2*x**3 + 3*x**2 # -2x^3 + 3x^2 # _/-\n",
        "def ACosine(x): return torch.acos(1-2*x)/torch.pi # /-/ # x = acos(1-2y)/pi\n",
        "def InvertCubic(x): return (x-1)**3+1 # /-\n",
        "def InvertExp(x, a=4): return (1-torch.exp(-a*x)) / (1-torch.exp(torch.tensor(-a))) # /-\n",
        "\n",
        "\n",
        "a, b = .0, 0\n",
        "def bezier(t, x0=0,y0=0, x1=a,y1=b, x2=1-a,y2=1-b, x3=1,y3=1):\n",
        "    # print(x1,y1)\n",
        "    # return ((1-t)*((1-t)*((1-t)*x0+t*x1)+t*((1-t)*x1+t*x2))+t*((1-t)*((1-t)*x1+t*x2)+t*((1-t)*x2+t*x3)), (1-t)*((1-t)*((1-t)*y0+t*y1) +t*((1-t)*y1+t*y2))+t*((1-t)*((1-t)*y1+t*y2) +t*((1-t)*y2+t*y3)))\n",
        "    return (1-t)*((1-t)*((1-t)*x0+t*x1)+t*((1-t)*x1+t*x2))+t*((1-t)*((1-t)*x1+t*x2)+t*((1-t)*x2+t*x3))\n",
        "    # return (1-t)*((1-t)*((1-t)*y0+t*y1) +t*((1-t)*y1+t*y2))+t*((1-t)*((1-t)*y1+t*y2) +t*((1-t)*y2+t*y3))\n",
        "\n",
        "\n",
        "# x = torch.linspace(0, 1, 30)\n",
        "# y=x\n",
        "# y = LogitNormalCDF(x, mu=0, std=3) # _/- for std<1.8; /-/ for std>1.8\n",
        "# y = Cosine(x) # _/-\n",
        "# y = ACosine(x) # /-/\n",
        "# y = Polynomial(x) # _/-\n",
        "# y = InvertCubic(x) # /-\n",
        "# y = InvertExp(x) # /-\n",
        "# y = bezier(x) # _/-\n",
        "# print(x, y)\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(x, y)\n",
        "# plt.show()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QRPa3VWuQDIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFc76OzlFnE1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Sampling save\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def reverse_flow(unet, cond, num_samples=1, timesteps=25): # [n_samples, cond_dim]\n",
        "    unet.eval()\n",
        "    i = torch.linspace(0, 1, timesteps+1)\n",
        "    # y = i # linear\n",
        "    # y = LogitNormalCDF(i, mu=0, std=3.) # .5 _/- for std<1.8; 3 /-/ for std>1.8\n",
        "    y = LogitNormalCDF(i, mu=-.0, std=2.7) # .5 _/- for std<1.8; 3 /-/ for std>1.8\n",
        "    # y = Cosine(i) # _/-\n",
        "    # y = ACosine(i) # /-/\n",
        "    # y = Polynomial(i) # _/-\n",
        "    # y = InvertCubic(i) # /-\n",
        "    # y = InvertExp(i) # /-\n",
        "    # y = bezier(i) # _/-\n",
        "\n",
        "    dt = y[1:]-y[:-1]\n",
        "    num_samples = cond.shape[0]\n",
        "    x = torch.randn((num_samples, unet.in_ch, 16,16), device=device)\n",
        "    # cond = cond.repeat(num_samples,1) # [n_samples, cond_dim]\n",
        "    for y, dt in zip(y, dt):\n",
        "        # print(y, dt)\n",
        "        t = torch.full((num_samples,), y, device=device)  # Current time # [num_samples] 1. # torch.tensor(i * dt, device=device).repeat(n_samples)\n",
        "        with torch.no_grad():\n",
        "            model = lambda y,t: -unet(y, t, cond)\n",
        "            v = model(x, t)\n",
        "            x = x - dt * v # Euler update # 25steps:1sec\n",
        "\n",
        "            # k1 = model(x, t)\n",
        "            # k2 = model(x - 0.5 * dt * k1, t - 0.5 * dt)\n",
        "            # k3 = model(x - 0.5 * dt * k2, t - 0.5 * dt)\n",
        "            # k4 = model(x - dt * k3, t - dt)\n",
        "            # x = x - (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4) # RK4 update # 25steps:4.5sec\n",
        "    return x\n",
        "\n",
        "\n",
        "# cond = F.one_hot(torch.tensor([3], device=device), num_classes=10).to(torch.float)\n",
        "# n_samples = 16\n",
        "# cond = F.one_hot(torch.arange(n_samples, device=device)%10, num_classes=10).to(torch.float)\n",
        "# sampled_data = reverse_flow(model, cond, n_samples, timesteps=10)\n",
        "# # sampled_data = model.sample(cond, n_samples = 1)\n",
        "\n",
        "# # plt.imshow(sampled_data.cpu().squeeze())\n",
        "# # plt.show()\n",
        "# imshow(torchvision.utils.make_grid(sampled_data.cpu(), nrow=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main"
      ],
      "metadata": {
        "id": "PbSq3Zx7aRL-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ1hbnSC12tA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PixelAE(nn.Module):\n",
        "    def __init__(self, in_ch=3, d_model=256, out_ch=None, kernels=[7,5], mult=[1]):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch = in_ch\n",
        "        self.in_ch, self.d_model, self.out_ch = in_ch, d_model, out_ch\n",
        "        d_list=[d_model*m for m in mult]\n",
        "        in_list, out_list = [in_ch, *d_list[:-1]], [*d_list[:-1], out_ch]\n",
        "        act = nn.GELU() # ReLU GELU SiLU\n",
        "        self.encoder = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            *[nn.Sequential(PixelShuffleConv(in_dim, out_dim, kernel, r=1/2), nn.BatchNorm2d(out_dim) if i!=len(d_list) else nn.Identity(), act,) for i, (in_dim, out_dim, kernel) in enumerate(zip(in_list, out_list, kernels))], # conv,norm,act except for last layer: no norm\n",
        "            # PixelShuffleConvDown(in_ch, d_list[0], 7, r=2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # PixelShuffleConvDown(d_list[0], d_list[1], 5, r=2), act,\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # *[nn.Sequential(PixelShuffleConv(in_dim, out_dim, kernel, r=2), nn.BatchNorm2d(out_dim) if i!=len(d_list) else nn.Identity(), act if i!=len(d_list) else nn.Identity()) for i, (in_dim, out_dim, kernel) in enumerate(zip(reversed(out_list), reversed(in_list), reversed(kernels)))], # conv,norm,act except for last layer: only conv\n",
        "            *[nn.Sequential(PixelShuffleConv(in_dim, out_dim, kernel, r=2), *(nn.BatchNorm2d(out_dim), act) if i!=len(d_list) else nn.Identity()) for i, (in_dim, out_dim, kernel) in enumerate(zip(reversed(out_list), reversed(in_list), reversed(kernels)))], # conv,norm,act except for last layer: only conv\n",
        "            # PixelShuffleConvUp(d_list[1], d_list[0], 5, r=2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # PixelShuffleConvUp(d_list[0], in_ch, 7, r=2), act,\n",
        "        )\n",
        "        # for param in self.parameters():\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "    def encode(self, x): return self.encoder(x)\n",
        "    def decode(self, x): return self.decoder(x)\n",
        "\n",
        "\n",
        "# in_ch=3\n",
        "# model_ch=16\n",
        "# d_list=[16, 16] # [16,32]\n",
        "# k_list=[7,5] # [7,5]\n",
        "# conv = Conv(in_ch=in_ch, d_list=d_list, k_list=k_list, act=nn.ReLU()) # ReLU GELU SiLU\n",
        "\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# conv = Conv().to(device)\n",
        "# print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "# input = torch.rand((4,3,64,64), device=device)\n",
        "# enc = conv(input)\n",
        "# print(enc.shape)\n",
        "# out = deconv(enc)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nvBRca98P-GW"
      },
      "outputs": [],
      "source": [
        "# @title latent flow model\n",
        "\n",
        "class LFM(nn.Module): # latent flow model\n",
        "    def __init__(self, in_ch=3, d_list=[16, 3], d_model=16, cond_dim=16, depth=3):\n",
        "        super().__init__()\n",
        "        self.ae = PixelAE(in_ch, d_model)\n",
        "        self.unet = UNet(in_ch=in_ch, d_model=d_model, cond_dim=cond_dim, depth=3)\n",
        "\n",
        "    def loss(self, img, cond): # [b,c,h,w], [b,cond_dim]\n",
        "        x1 = self.ae.encode(img)\n",
        "        img_ = self.ae.decode(x1)\n",
        "        ae_loss = F.mse_loss(img_, img)\n",
        "        fm_loss = otfm_loss(self.unet, x1.detach(), cond)\n",
        "        return ae_loss, fm_loss\n",
        "        # loss = ae_loss + fm_loss\n",
        "        # return loss\n",
        "\n",
        "    def ae_loss(self, img):\n",
        "        img_ = self.ae(img)\n",
        "        ae_loss = F.mse_loss(img_, img)\n",
        "        return ae_loss\n",
        "\n",
        "\n",
        "    # self.unet(x, t=None, cond=None)\n",
        "    # def forward(self, cond, timesteps=10): # [N, C, ...]\n",
        "    def sample(self, cond=None, n_samples=16, timesteps=10):\n",
        "        self.eval()\n",
        "        # cond = F.one_hot(torch.tensor([4], device=device), num_classes=10).to(torch.float)\n",
        "        # if cond is None: cond = F.one_hot(torch.arange(n_samples, dtype=torch.float, device=device)%10, num_classes=10).to(torch.float)\n",
        "        n_samples = cond.shape[0]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x1_ = reverse_flow(self.unet, cond, n_samples, timesteps=timesteps)\n",
        "            img_ = self.ae.decode(x1_)\n",
        "        return img_\n",
        "\n",
        "model = LFM(d_list=[16, 16], d_model=16, cond_dim=10, depth=3).to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=3e-3) # 1e-3 3e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfsabyM8P7q3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c71cf09-cc3a-4456-dcd6-23197388f592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.009836817160248756 0.06047654151916504\n",
            "10 0.00913749635219574 0.05989290401339531\n"
          ]
        }
      ],
      "source": [
        "# @title train\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.GradScaler(device)\n",
        "\n",
        "def otfm_loss(model, x1, cond, sig_min = 0.001, eps = 1e-5): # UNetModel, [b,c,h,w], [b,cond_dim] # https://github.com/lebellig/flow-matching/blob/main/Flow_Matching.ipynb\n",
        "    batch = x1.size(0)\n",
        "    # t = torch.rand((batch,), device=device) % (1 - eps)\n",
        "    t = logit_normal.rsample((batch,)).to(device) # in [0,1] [batch,1]\n",
        "    t_ = t[...,None,None,None]\n",
        "    x0 = torch.randn_like(x1)\n",
        "    psi_t = (1 - (1-sig_min)*t_)*x0 + t_*x1 # ψt(x) = (1 − (1 − σmin)t)x + tx1, (22)\n",
        "    v_psi = model(psi_t, t, cond) # vt(ψt(x0))\n",
        "    d_psi = x1 - (1 - sig_min) * x0 #\n",
        "    return F.mse_loss(v_psi, d_psi) # LCFM(θ)\n",
        "\n",
        "\n",
        "def train(model, optim, dataloader):\n",
        "    model.train()\n",
        "    for i, (x1, y) in enumerate(dataloader):\n",
        "        x1, y = x1.to(device), y.to(device)\n",
        "        # cond = cond_emb(y)\n",
        "        cond = F.one_hot(y, num_classes=10).to(torch.float)\n",
        "\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16): # float16 cannot?\n",
        "            # x1 = F.interpolate(x1, size=(16,16))#.repeat(1,3,1,1)\n",
        "            # loss = otfm_loss(model, x1, cond) # unet\n",
        "            img = F.interpolate(x1, size=(64,64)).repeat(1,3,1,1)\n",
        "            # # loss = model.ae_loss(x1)\n",
        "            # ae_loss, fm_loss = model.loss(x1, cond)\n",
        "\n",
        "            x1 = model.ae.encode(img)\n",
        "            img_ = model.ae.decode(x1)\n",
        "\n",
        "            ae_loss = F.mse_loss(img_, img)\n",
        "            fm_loss = otfm_loss(model.unet, x1.detach(), cond)\n",
        "\n",
        "            loss = ae_loss + fm_loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # clip gradients\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        # optim.zero_grad()\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "\n",
        "        # if i % 10 == 0: print(i,loss.item())\n",
        "        if i % 10 == 0:\n",
        "            # imshow(torchvision.utils.make_grid(x1[:4].detach().cpu().to(torch.float32), nrow=4))\n",
        "            # imshow(torchvision.utils.make_grid(img_[:4].detach().cpu().to(torch.float32), nrow=4))\n",
        "            print(i,ae_loss.item(), fm_loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        try: wandb.log({\"ae_loss\": ae_loss.item(), \"fm_loss\": fm_loss.item()})\n",
        "        except: pass\n",
        "\n",
        "# x1 = F.interpolate(x1, size=(28,28))\n",
        "# F.avg_pool2d(input, kernel_size, stride=None, padding=0)\n",
        "\n",
        "for epoch in range(40):\n",
        "# for epoch in range(1):\n",
        "    train(model, optim, train_loader)\n",
        "\n",
        "    for x,y in test_loader: break\n",
        "    img = F.interpolate(x.to(device), size=(64,64)).repeat(1,3,1,1)\n",
        "    x1 = model.ae.encode(img)\n",
        "    img_ = model.ae.decode(x1)\n",
        "    imshow(torchvision.utils.make_grid(x1[:4].detach().cpu().to(torch.float32), nrow=4))\n",
        "    imshow(torchvision.utils.make_grid(img_[:4].detach().cpu().to(torch.float32), nrow=4))\n",
        "\n",
        "    # # cond = F.one_hot(torch.tensor([4], device=device), num_classes=10).expand(16,-1).to(torch.float)\n",
        "    cond = F.one_hot(torch.arange(16, device=device)%10, num_classes=10).to(torch.float)\n",
        "    img_ = model.sample(cond, timesteps=10)\n",
        "    imshow(torchvision.utils.make_grid(img_.cpu(), nrow=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkLzZo4BU3MK",
        "outputId": "eb02396d-442c-423e-e805-3688f356517d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.8268,  0.9299,  ...,  0.8252,  0.5075,  0.5760],\n",
            "          [ 0.6185,  0.9110,  1.1500,  ...,  1.0880,  0.6892,  0.4957],\n",
            "          [ 0.7144,  1.6515,  3.1023,  ...,  3.1522,  1.9055,  1.1132],\n",
            "          ...,\n",
            "          [ 0.7460,  1.3835,  1.2860,  ...,  1.5332,  1.0094,  0.8710],\n",
            "          [ 1.2005,  1.8461,  1.9205,  ...,  2.1597,  1.6642,  1.5685],\n",
            "          [ 1.9763,  2.1883,  2.4338,  ...,  2.4918,  1.9622,  1.5289]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.8819,  0.8633,  ...,  0.7973,  0.5075,  0.5760],\n",
            "          [ 0.5887,  0.7754,  0.9495,  ...,  0.8854,  0.5897,  0.4406],\n",
            "          [ 0.7467,  1.1403,  2.5462,  ...,  1.2472,  1.0147,  0.8710],\n",
            "          ...,\n",
            "          [ 0.7460,  1.3101,  2.1215,  ...,  2.4408,  1.7315,  1.7638],\n",
            "          [ 1.2005,  1.9463,  2.3494,  ...,  4.2847,  2.5810,  2.1600],\n",
            "          [ 1.9763,  2.2174,  2.5992,  ...,  2.4267,  2.2756,  1.6146]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.8357,  0.8252,  ...,  1.1309,  0.5493,  0.5760],\n",
            "          [ 0.5904,  0.8840,  0.9693,  ...,  1.7355,  0.6502,  0.4406],\n",
            "          [ 0.7460,  1.3835,  1.4523,  ...,  2.0061,  1.0694,  0.8710],\n",
            "          ...,\n",
            "          [ 0.7460,  1.3835,  1.4405,  ...,  1.4523,  1.0147,  0.8710],\n",
            "          [ 1.2005,  1.8461,  2.1686,  ...,  2.1738,  1.6642,  1.5685],\n",
            "          [ 1.9763,  2.1883,  2.4962,  ...,  2.4941,  1.9623,  1.5289]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.8357,  0.8252,  ...,  0.8714,  0.5075,  0.5760],\n",
            "          [ 0.5904,  0.8840,  0.9417,  ...,  0.8978,  0.5897,  0.4406],\n",
            "          [ 0.7460,  1.3784,  1.4516,  ...,  1.2860,  1.0147,  0.8710],\n",
            "          ...,\n",
            "          [ 0.7460,  1.3991,  1.5236,  ...,  3.3257,  2.3552,  1.0811],\n",
            "          [ 1.2005,  1.8462,  2.1756,  ...,  4.3642,  2.1633,  1.8221],\n",
            "          [ 1.9763,  2.1883,  2.4941,  ...,  3.1248,  2.4156,  1.6927]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.8182,  0.8448,  ...,  0.8455,  0.5075,  0.5760],\n",
            "          [ 0.5629,  0.9416,  0.9319,  ...,  0.9880,  0.6291,  0.4406],\n",
            "          [ 0.7228,  1.4928,  2.0840,  ...,  1.8701,  1.1114,  0.8929],\n",
            "          ...,\n",
            "          [ 0.7534,  1.6909,  2.5332,  ...,  4.2433,  1.9605,  1.6216],\n",
            "          [ 1.1866,  2.0016,  2.8804,  ...,  2.6695,  2.0529,  1.6442],\n",
            "          [ 2.0065,  2.2066,  2.6341,  ...,  2.6812,  2.1354,  1.5543]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.8357,  0.8252,  ...,  1.7013,  0.7722,  1.2491],\n",
            "          [ 0.5847,  0.8588,  0.9494,  ...,  1.9336,  2.4857,  0.2364],\n",
            "          [ 0.7208,  1.3400,  1.5916,  ..., 17.5788,  7.0052,  0.0000],\n",
            "          ...,\n",
            "          [ 0.7460,  1.2238,  2.7033,  ...,  1.7982,  1.0403,  0.8710],\n",
            "          [ 1.2005,  1.8236,  2.7293,  ...,  2.3239,  1.6690,  1.5685],\n",
            "          [ 1.9763,  2.2759,  2.6086,  ...,  2.6803,  1.9582,  1.5289]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
            "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test func\n",
        "\n",
        "def test(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss=0\n",
        "    for i, (x1, y) in enumerate(dataloader):\n",
        "        x1, y = x1.to(device), y.to(device)\n",
        "        # cond = cond_emb(y)\n",
        "        cond = F.one_hot(y, num_classes=10).to(torch.float)\n",
        "\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16): # float16 cannot?\n",
        "            # x1 = F.interpolate(x1, size=(64,64)).repeat(1,3,1,1)\n",
        "            # ae_loss, fm_loss = model.loss(x1, cond)\n",
        "            # loss = ae_loss + fm_loss\n",
        "            x1 = F.interpolate(x1, size=(16,16))#.repeat(1,3,1,1)\n",
        "            loss = otfm_loss(model, x1, cond) # unet\n",
        "        total_loss+=loss\n",
        "    print(total_loss/len(dataloader))\n",
        "    # if i % 10 == 0: print(i,ae_loss.item(),fm_loss.item())\n",
        "    try: wandb.log({\"test_loss\": loss.item()})\n",
        "    # try: wandb.log({\"ae_loss\": ae_loss.item(), \"fm_loss\": fm_loss.item()})\n",
        "    except: pass\n",
        "\n",
        "\n",
        "# test(model, test_loader)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ecSX2oJJ4_2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "2Nd-sGe6Ku4S",
        "outputId": "1e0abac3-1ebc-4096-a69b-13c2ec0b3b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250301_100250-davsz0u4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/lfm/runs/davsz0u4' target=\"_blank\">earnest-puddle-41</a></strong> to <a href='https://wandb.ai/bobdole/lfm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/lfm' target=\"_blank\">https://wandb.ai/bobdole/lfm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/lfm/runs/davsz0u4' target=\"_blank\">https://wandb.ai/bobdole/lfm/runs/davsz0u4</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "!pip install -q wandb\n",
        "import wandb # https://docs.wandb.ai/quickstart\n",
        "wandb.login(key='487a2109e55dce4e13fc70681781de9f50f27be7')\n",
        "try: run.finish()\n",
        "except NameError: pass\n",
        "run = wandb.init(project=\"lfm\", config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGN0e0Mxe5UI",
        "outputId": "089d320d-ee1b-4a1d-b1fa-4ad317c419c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-23f3dbda76f1>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  modelsd, optimsd = torch.load(folder+'lfm.pkl', map_location=device).values()\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "\n",
        "modelsd, optimsd = torch.load(folder+'lfm.pkl', map_location=device).values()\n",
        "model.load_state_dict(modelsd, strict=False)\n",
        "optim.load_state_dict(optimsd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrFxTtw4eFSq"
      },
      "outputs": [],
      "source": [
        "checkpoint = {'model': model.state_dict(), 'optimizer': optim.state_dict()}\n",
        "torch.save(checkpoint, folder+'lfm.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# High Fidelity Visualization of What Your Self-Supervised Representation Knows About aug 2022\n",
        "# https://arxiv.org/pdf/2112.09164\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DVSdLd7um-Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "nFhmfVnrOiQd",
        "outputId": "afac72cb-1f69-4c2d-bcac-30601773f70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.4052554..1.1741712].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 64, 64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # dataiter = iter(train_data)\n",
        "# x,y = next(dataiter)\n",
        "# # print(x)\n",
        "# print(x.shape)\n",
        "# x=x.unsqueeze(0)\n",
        "# # x1 = F.interpolate(x, size=(16,16))#.repeat(1,3,1,1)\n",
        "# x1 = F.interpolate(x, size=(64,64)).repeat(1,3,1,1)\n",
        "# imshow(torchvision.utils.make_grid(x1.cpu(), nrow=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save"
      ],
      "metadata": {
        "id": "IQlJ4XVLrOSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title unet me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# torch.set_default_dtype(torch.float16)\n",
        "\n",
        "import inspect\n",
        "class Seq(nn.Sequential):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "        for layer in self:\n",
        "            params = inspect.signature(layer.forward).parameters.keys()\n",
        "            layer._fwdparams = ','.join(params)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        for layer in self:\n",
        "            args = [x]\n",
        "            if 'emb' in layer._fwdparams: args.append(emb)\n",
        "            if 'cond' in layer._fwdparams: args.append(cond)\n",
        "            x = layer(*args)\n",
        "        return x\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None, emb_dim=None, drop=0.):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch=in_ch\n",
        "        act = nn.SiLU() #\n",
        "        self.block1 = nn.Sequential(nn.BatchNorm2d(in_ch), act, nn.Conv2d(in_ch, out_ch, 3, padding=1))\n",
        "        self.block2 = Seq(nn.BatchNorm2d(out_ch), scale_shift(out_ch, emb_dim) if emb_dim != None else nn.Identity(), act, nn.Conv2d(out_ch, out_ch, 3, padding=1))\n",
        "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, emb=None): # [b,c,h,w], [batch, emb_dim]\n",
        "        h = self.block1(x)\n",
        "        h = self.block2(h, emb)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class scale_shift(nn.Module): # FiLM\n",
        "    def __init__(self, x_dim, t_dim):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(nn.SiLU(), nn.Linear(t_dim, x_dim*2),)\n",
        "\n",
        "    def forward(self, x, emb): # [b,c,h,w], [b,emb_dim]\n",
        "        scale, shift = self.time_mlp(emb)[..., None, None].chunk(2, dim=1) # [b,t_dim]->[b,2*x_dim,1,1]->[b,x_dim,1,1]\n",
        "        return x * (scale + 1) + shift\n",
        "\n",
        "class levelBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, emb_dim, cond_dim, n_head=None, d_head=8, updown=False, r=2):\n",
        "        super().__init__()\n",
        "        if updown=='down': in_ch = in_ch*r**2\n",
        "        elif updown=='up': out_ch = out_ch*r**2\n",
        "        if n_head==None: n_head = out_ch // d_head\n",
        "        layers = [\n",
        "            nn.PixelUnshuffle(r) if updown=='down' else nn.Identity(),\n",
        "            ResBlock(in_ch, out_ch, emb_dim=emb_dim),\n",
        "            AttentionBlock(out_ch, d_head, cond_dim),\n",
        "            nn.PixelShuffle(r) if updown=='up' else nn.Identity(),\n",
        "            ]\n",
        "        self.seq = Seq(*layers)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        return self.seq(x, emb, cond)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, d_model=16, out_ch=None, cond_dim=16, depth=4, num_res_blocks=1, n_head=-1, d_head = 4):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.d_model = d_model # base channel count for the model\n",
        "        out_ch = out_ch or in_ch\n",
        "        n_head = d_model // d_head\n",
        "\n",
        "        self.rotemb = RotEmb(d_model)\n",
        "        emb_dim = d_model# * 4\n",
        "        self.time_emb = nn.Sequential(nn.Linear(d_model, emb_dim), nn.SiLU(), nn.Linear(emb_dim, emb_dim))\n",
        "\n",
        "\n",
        "        tok_dim = d_model\n",
        "        # if tok_dim == None: tok_dim = d_model\n",
        "        self.num_time_tokens = 2\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            RotEmb(emb_dim, top=torch.pi, base=10000),\n",
        "            nn.Linear(emb_dim, emb_dim), nn.SiLU(),\n",
        "            nn.Linear(emb_dim, emb_dim + self.num_time_tokens * tok_dim),\n",
        "        )\n",
        "        self.emb_dim, self.tok_dim = emb_dim, tok_dim\n",
        "        self.cond_mlp = nn.Sequential(\n",
        "            nn.LayerNorm(cond_dim), nn.Linear(cond_dim, emb_dim), nn.SiLU(),\n",
        "            nn.Linear(emb_dim, emb_dim + tok_dim)\n",
        "        )\n",
        "        self.norm_cond = nn.LayerNorm(tok_dim)\n",
        "        cond_dim = tok_dim\n",
        "\n",
        "\n",
        "        self.in_block = nn.Sequential(nn.Conv2d(in_ch, d_model, 3, padding=1))\n",
        "        # self.in_block = nn.Sequential(nn.Conv2d(in_ch, d_model, 3, padding=1), act)\n",
        "        # self.init_conv = CrossEmbedLayer(in_ch, dim_out=d_model, kernel_sizes=(3, 7, 15), stride=1) #if init_cross_embed else nn.Conv2d(in_ch, d_model, 7, padding = 7//2)\n",
        "\n",
        "        dim_mults = [1,2,3,4,4] # [1,2,3,4] [1,2,2,2]\n",
        "        ch_list = [d_model * m for m in dim_mults] # [128, 256, 384, 512]\n",
        "        # in_out = list(zip(dims[:-1], dims[1:]))\n",
        "        # for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "\n",
        "\n",
        "        self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], emb_dim, cond_dim, updown=None if i==0 else 'down') for i in range(depth)])\n",
        "        # self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], emb_dim, cond_dim, updown='down') for i in range(depth)])\n",
        "\n",
        "        ch = ch_list[-1]*2**2 # 512\n",
        "        self.middle_block = Seq(\n",
        "            nn.PixelUnshuffle(2), ResBlock(ch, ch, emb_dim),\n",
        "            AttentionBlock(ch, d_head, cond_dim),\n",
        "            ResBlock(ch, ch, emb_dim), nn.PixelShuffle(2),\n",
        "        )\n",
        "        self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], emb_dim, cond_dim, updown=None if i==0 else 'up') for i in reversed(range(depth))])\n",
        "        # self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], emb_dim, cond_dim, updown='up') for i in reversed(range(depth))])\n",
        "        # for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
        "\n",
        "        self.out_block = nn.Sequential(nn.BatchNorm2d(d_model), nn.SiLU(), nn.Conv2d(d_model, out_ch, 3, padding=1)) # zero\n",
        "        # self.final_conv = nn.Conv2d(d_model, self.out_ch, 3, padding = 3//2) # lucid; or prepend final res block\n",
        "\n",
        "    def forward(self, x, t=None, cond=None): # [N, c,h,w], [N], [N, cond_dim]\n",
        "        # t_emb = self.rotemb(t)\n",
        "        # emb = self.time_emb(t_emb) #+ self.label_emb(y) # class conditioning nn.Embedding(num_classes, emb_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        t_hid, t_tok = self.time_mlp(t).split([self.emb_dim, self.num_time_tokens * self.tok_dim], dim=-1)\n",
        "        t_tok = t_tok.reshape(t_tok.shape[0], self.num_time_tokens, self.tok_dim)\n",
        "        c_hid, c_tok = self.cond_mlp(cond).split([self.emb_dim, self.tok_dim], dim=-1)\n",
        "        # print('unet fwd', t_hid.shape, t_tok.shape, t.shape)\n",
        "\n",
        "        emb = t_hid + c_hid # [batch, emb_dim]\n",
        "        cond = torch.cat((t_tok, c_tok.unsqueeze(1)), dim=-2) # [b, num_toks, tok_dim]\n",
        "        cond = self.norm_cond(cond)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        blocks = []\n",
        "        x = self.in_block(x)\n",
        "        for i, down in enumerate(self.down_list):\n",
        "            x = down(x, emb, cond)\n",
        "            blocks.append(x)\n",
        "        x = self.middle_block(x, emb, cond)\n",
        "        for i, up in enumerate(self.up_list):\n",
        "            # print(\"unet fwd\", x.shape,blocks[-i-1].shape)\n",
        "            x = torch.cat([x, blocks[-i-1]*2**.5], dim=1) # scale residuals by 1/sqrt2\n",
        "            x = up(x, emb, cond) # x = up(x, blocks[-i - 1])\n",
        "        return self.out_block(x)\n",
        "\n",
        "\n",
        "\n",
        "# 64,64 -vae-> 16,16 -unet->\n",
        "batch = 4\n",
        "cond_dim=10\n",
        "model = UNet(in_ch=1, d_model=16, cond_dim=cond_dim, depth=3).to(device)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# print(model)\n",
        "\n",
        "# x=torch.rand((batch,3,16,16),device=device)\n",
        "x=torch.rand((batch,1,16,16),device=device)\n",
        "# y=torch.rand((batch,1,16,16),device=device)\n",
        "t = torch.rand((batch,), device=device) # in [0,1] [N]\n",
        "# print(t)\n",
        "cond=torch.rand((batch,cond_dim),device=device)\n",
        "# [2, 1, 16, 16]) torch.Size([2]) torch.Size([2, 10]\n",
        "print(x.shape,t.shape,cond.shape)\n",
        "out = model(x, t, cond)\n",
        "print(out.shape)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3) # 1e-3 3e-3\n",
        "\n",
        "cond_emb = nn.Embedding(10, cond_dim).to(device)\n",
        "# for name, param in model.named_parameters(): print(name, param)\n",
        "# optim.zero_grad()\n",
        "# loss = F.mse_loss(out, y)\n",
        "# loss.backward()\n",
        "# optim.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1333af4-b45d-4774-918e-1c71098cd4e2",
        "cellView": "form",
        "id": "SlxB9mFM6abU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5323509\n",
            "torch.Size([4, 1, 16, 16]) torch.Size([4]) torch.Size([4, 10])\n",
            "torch.Size([4, 1, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_ch=3, d_list=[32, 64], k_list=[7,5], act=nn.GELU(), drop=0.): # ReLU GELU SiLU\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            PixelShuffleConv(in_ch, d_list[0], k_list[0], r=1/2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            nn.Dropout2d(drop), PixelShuffleConv(d_list[0], d_list[1], k_list[1], r=1/2), act,\n",
        "        )\n",
        "    def forward(self, x): return self.conv(x) # [batch, 3,64,64] -> [batch, c,h,w]\n",
        "\n",
        "class Deconv(nn.Module):\n",
        "    def __init__(self, out_ch=3, d_list=[32, 64], k_list=[7,5], act=nn.GELU(), drop=0.): # ReLU GELU SiLU\n",
        "        super().__init__()\n",
        "        self.deconv = nn.Sequential(\n",
        "            PixelShuffleConv(d_list[1], d_list[0], k_list[1], r=2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            PixelShuffleConv(d_list[0], out_ch, k_list[0], r=2),\n",
        "        )\n",
        "    def forward(self, x): return self.deconv(x) # [batch, c,h,w] -> [batch, 3,64,64]\n",
        "\n",
        "\n",
        "class PixelAE(nn.Module):\n",
        "    def __init__(self, in_ch=3, d_model=256, out_ch=None, kernels=[7,5], mult=[1]):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch = in_ch\n",
        "        self.in_ch, self.d_model, self.out_ch = in_ch, d_model, out_ch\n",
        "        d_list=[d_model*m for m in mult]\n",
        "        in_list, out_list = [in_ch, *d_list[:-1]], [*d_list[:-1], out_ch]\n",
        "        act = nn.GELU() # ReLU GELU SiLU\n",
        "        self.encoder = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            *[nn.Sequential(PixelShuffleConv(in_dim, out_dim, kernel, r=1/2), nn.BatchNorm2d(out_dim) if i!=len(d_list) else nn.Identity(), act,) for i, (in_dim, out_dim, kernel) in enumerate(zip(in_list, out_list, kernels))], # conv,norm,act except for last layer: no norm\n",
        "            # PixelShuffleConvDown(in_ch, d_list[0], 7, r=2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # PixelShuffleConvDown(d_list[0], d_list[1], 5, r=2), act,\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            # *[nn.Sequential(PixelShuffleConv(in_dim, out_dim, kernel, r=2), nn.BatchNorm2d(out_dim) if i!=len(d_list) else nn.Identity(), act if i!=len(d_list) else nn.Identity()) for i, (in_dim, out_dim, kernel) in enumerate(zip(reversed(out_list), reversed(in_list), reversed(kernels)))], # conv,norm,act except for last layer: only conv\n",
        "            *[nn.Sequential(PixelShuffleConv(in_dim, out_dim, kernel, r=2), *(nn.BatchNorm2d(out_dim), act) if i!=len(d_list) else nn.Identity()) for i, (in_dim, out_dim, kernel) in enumerate(zip(reversed(out_list), reversed(in_list), reversed(kernels)))], # conv,norm,act except for last layer: only conv\n",
        "            # PixelShuffleConvUp(d_list[1], d_list[0], 5, r=2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # PixelShuffleConvUp(d_list[0], in_ch, 7, r=2), act,\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "    def encode(self, x): return self.encoder(x)\n",
        "    def decode(self, x): return self.decoder(x)\n",
        "\n",
        "\n",
        "# in_ch=3\n",
        "# model_ch=16\n",
        "# d_list=[16, 16] # [16,32]\n",
        "# k_list=[7,5] # [7,5]\n",
        "# conv = Conv(in_ch=in_ch, d_list=d_list, k_list=k_list, act=nn.ReLU()) # ReLU GELU SiLU\n",
        "\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# conv = Conv().to(device)\n",
        "# print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "# input = torch.rand((4,3,64,64), device=device)\n",
        "# enc = conv(input)\n",
        "# print(enc.shape)\n",
        "# out = deconv(enc)\n",
        "# print(out.shape)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EkVBxwyjTpM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMFVOgT4sJ-y",
        "outputId": "4cbee834-bd46-4ad0-8123-69552b7cdac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13204529\n"
          ]
        }
      ],
      "source": [
        "# @title stable diffusion unet next\n",
        "# https://github.com/CompVis/latent-diffusion/blob/main/ldm/modules/diffusionmodules/openaimodel.py#L413\n",
        "# is from https://github.com/openai/guided-diffusion/blob/main/guided_diffusion/unet.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# torch.set_default_dtype(torch.float16)\n",
        "\n",
        "import inspect\n",
        "class Seq(nn.Sequential):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "        for layer in self:\n",
        "            params = inspect.signature(layer.forward).parameters.keys()\n",
        "            layer._fwdparams = ','.join(params)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        for layer in self:\n",
        "            args = [x]\n",
        "            if 'emb' in layer._fwdparams: args.append(emb)\n",
        "            if 'cond' in layer._fwdparams: args.append(cond)\n",
        "            x = layer(*args)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None):\n",
        "        super().__init__()\n",
        "        if out_ch == None: out_ch = in_ch\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 3, padding=1) # og\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), act)\n",
        "\n",
        "    def forward(self, x): # [N,C,...]\n",
        "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\") # if self.conv_dim == 3: x = F.interpolate(x, (x.shape[2], x.shape[3] * 2, x.shape[4] * 2), mode=\"nearest\")\n",
        "        x = self.conv(x) # optional\n",
        "        return x\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch = in_ch\n",
        "        self.op = nn.Conv2d(in_ch, out_ch, 3, stride=2, padding=1) # optional # stride = 2 if conv_dim != 3 else (1, 2, 2) # If 3D, then downsampling occurs in the inner-two dimensions\n",
        "        self.op = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, stride=2, padding=1), act)\n",
        "        # self.op = avg_pool_nd(conv_dim, kernel_size=stride, stride=stride) # alternative\n",
        "\n",
        "    def forward(self, x): # [N,C,*spatial]\n",
        "        return self.op(x)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, temb_dim, out_ch=None, scale_shift=False, updown=False, drop=0.):\n",
        "        super().__init__()\n",
        "        self.temb_dim = temb_dim # number of timestep embedding channels\n",
        "        if out_ch == None: out_ch = in_ch\n",
        "        self.in_ch, self.out_ch = in_ch, out_ch\n",
        "        self.scale_shift = scale_shift\n",
        "        if updown=='up': self.h_upd, self.x_upd = Upsample(in_ch), Upsample(in_ch)\n",
        "        elif updown=='down': self.h_upd, self.x_upd = Downsample(in_ch), Downsample(in_ch)\n",
        "        else: self.h_upd = self.x_upd = nn.Identity()\n",
        "        self.in_layers = nn.Sequential(nn.BatchNorm2d(in_ch), nn.SiLU(), self.h_upd, nn.Conv2d(in_ch, out_ch, 3, padding=1),) # zero\n",
        "        # self.in_layers = nn.Sequential(self.h_upd, nn.Conv2d(in_ch, out_ch, 3, padding=1)) # no bn before FiLM\n",
        "        # self.in_layers = nn.Sequential(self.h_upd, nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.SiLU(), self.h_upd, nn.Conv2d(out_ch, out_ch, 3, padding=1)) # no bn before FiLM\n",
        "\n",
        "        # Conv bn film act res\n",
        "        self.emb_layers = nn.Sequential(nn.SiLU(), nn.Linear(temb_dim, 2 * out_ch if scale_shift else out_ch),)\n",
        "        # self.emb_layers = nn.Sequential(nn.Linear(temb_dim, out_ch), nn.SiLU(), nn.Linear(out_ch, 2 * out_ch if scale_shift else out_ch),)\n",
        "        self.out_layers = nn.Sequential(\n",
        "            nn.BatchNorm2d(out_ch), nn.SiLU(), nn.Dropout(drop), nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            # nn.BatchNorm2d(out_ch), nn.SiLU(), nn.Dropout(drop), zero_module(nn.Conv2d(out_ch, out_ch, 3, padding=1)),\n",
        "        )\n",
        "\n",
        "        if out_ch == in_ch: self.skip = nn.Identity() # no need to change chanels\n",
        "        else:\n",
        "            # self.skip = nn.Conv2d(in_ch, out_ch, 3, padding=1) # spatial convolution to change the channels in the skip connection\n",
        "            self.skip = nn.Conv2d(in_ch, out_ch, 1) # smaller 1x1 convolution to change the channels in the skip connection\n",
        "\n",
        "    def forward(self, x, emb): # [N, C, ...], [N, temb_dim]\n",
        "        # print(\"res fwd x\", x.shape, self.in_ch, self.out_ch)\n",
        "        h = self.in_layers(x) # norm, act, h_upd, conv\n",
        "        x = self.x_upd(x)\n",
        "        emb_out = self.emb_layers(emb) # act, lin\n",
        "        # print(\"res fwd h emb_out\", h.shape, emb_out.shape)\n",
        "        while len(emb_out.shape) < len(h.shape): emb_out = emb_out[..., None]\n",
        "        if self.scale_shift: # FiLM\n",
        "            out_norm, out_rest = self.out_layers[0], self.out_layers[1:]\n",
        "            scale, shift = torch.chunk(emb_out, 2, dim=1)\n",
        "            h = out_norm(h) * (1 + scale) + shift\n",
        "            h = out_rest(h) # act, drop, conv\n",
        "        else:\n",
        "            h = h + emb_out\n",
        "            h = self.out_layers(h)\n",
        "        return h + self.skip(x) # [N, C, ...]\n",
        "\n",
        "\n",
        "class levelBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, temb_dim, cond_dim, n_head=None, d_head=8, updown=False, *args):\n",
        "        super().__init__()\n",
        "        if n_head==None: n_head = out_ch // d_head\n",
        "        layers = [\n",
        "            # Downsample(in_ch, out_ch) if updown=='down' else nn.Identity(),\n",
        "            Downsample(in_ch) if updown=='down' else nn.Identity(),\n",
        "            ResBlock(in_ch, temb_dim, out_ch=out_ch),\n",
        "            # SpatialTransformer(out_ch, n_head, d_head, depth=1, cond_dim=cond_dim),\n",
        "            AttentionBlock(out_ch, d_head, cond_dim),\n",
        "            Upsample(out_ch) if updown=='up' else nn.Identity(),\n",
        "            # Upsample(in_ch, out_ch) if updown=='up' else nn.Identity(),\n",
        "            ]\n",
        "        self.seq = Seq(*layers)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        return self.seq(x, emb, cond)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, model_ch=16, out_ch=None, cond_dim=16, depth=4, num_res_blocks=1, n_head=-1, d_head = 4):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.model_ch = model_ch # base channel count for the model\n",
        "        out_ch = out_ch or in_ch\n",
        "        n_head = model_ch // d_head\n",
        "\n",
        "        self.rotemb = RotEmb(model_ch)\n",
        "        temb_dim = model_ch# * 4\n",
        "        self.time_emb = nn.Sequential(nn.Linear(model_ch, temb_dim), nn.SiLU(), nn.Linear(temb_dim, temb_dim))\n",
        "\n",
        "        self.in_block = nn.Sequential(nn.Conv2d(in_ch, model_ch, 3, padding=1))\n",
        "        # self.in_block = nn.Sequential(nn.Conv2d(in_ch, model_ch, 3, padding=1), act)\n",
        "\n",
        "        ch_list = [model_ch*2**i for i in range(depth+1)] # [32, 64, 128, 256]\n",
        "        self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], temb_dim, cond_dim, updown=None if i==0 else 'down') for i in range(depth)])\n",
        "        # self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], temb_dim, cond_dim, updown='down') for i in range(depth)])\n",
        "\n",
        "        ch = 2*ch_list[-1] # 512\n",
        "        self.middle_block = Seq(\n",
        "            Downsample(ch_list[-1]),\n",
        "            ResBlock(ch_list[-1], temb_dim, ch),\n",
        "            # SpatialTransformer(ch, ch//d_head, d_head, cond_dim=cond_dim),\n",
        "            AttentionBlock(ch, d_head, cond_dim),\n",
        "            ResBlock(ch, temb_dim, ch_list[-1]),\n",
        "            Upsample(ch_list[-1]),\n",
        "        )\n",
        "        self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], temb_dim, cond_dim, updown=None if i==0 else 'up') for i in reversed(range(depth))])\n",
        "        # self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], temb_dim, cond_dim, updown='up') for i in reversed(range(depth))])\n",
        "\n",
        "        self.out_block = nn.Sequential(nn.BatchNorm2d(model_ch), nn.SiLU(), nn.Conv2d(model_ch, out_ch, 3, padding=1)) # zero\n",
        "\n",
        "    def forward(self, x, t=None, cond=None): # [N, c,h,w], [N], [N, cond_dim]\n",
        "        t_emb = self.rotemb(t)\n",
        "        # t_emb = timestep_embedding(t, self.model_ch, repeat_only=False)\n",
        "        emb = self.time_emb(t_emb)\n",
        "        # emb = emb + self.label_emb(y) # class conditioning nn.Embedding(num_classes, temb_dim)\n",
        "        blocks = []\n",
        "        x = self.in_block(x)\n",
        "        for i, down in enumerate(self.down_list):\n",
        "            x = down(x, emb, cond)\n",
        "            blocks.append(x)\n",
        "        x = self.middle_block(x, emb, cond)\n",
        "        for i, up in enumerate(self.up_list):\n",
        "            # print(\"unet fwd\", x.shape,blocks[-i-1].shape)\n",
        "            x = torch.cat([x, blocks[-i-1]*2**.5], dim=1)\n",
        "            x = up(x, emb, cond) # x = up(x, blocks[-i - 1])\n",
        "        return self.out_block(x)\n",
        "\n",
        "\n",
        "\n",
        "# 64,64 -vae-> 16,16 -unet->\n",
        "batch = 4\n",
        "cond_dim=10\n",
        "model = UNet(in_ch=1, model_ch=16, cond_dim=cond_dim, depth=4).to(device)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# print(model)\n",
        "\n",
        "# # x=torch.rand((batch,3,16,16),device=device)\n",
        "# x=torch.rand((batch,1,16,16),device=device)\n",
        "# y=torch.rand((batch,1,16,16),device=device)\n",
        "# t = torch.rand((batch,), device=device) # in [0,1] [N]\n",
        "# # print(t)\n",
        "# cond=torch.rand((batch,cond_dim),device=device)\n",
        "# # [2, 1, 16, 16]) torch.Size([2]) torch.Size([2, 10]\n",
        "# print(x.shape,t.shape,cond.shape)\n",
        "# out = model(x, t, cond)\n",
        "# print(out.shape)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3) # 1e-3 3e-3\n",
        "# optim = torch.optim.SGD(model.parameters(), lr=1e-4) # 1e-3 3e-3\n",
        "\n",
        "cond_emb = nn.Embedding(10, cond_dim).to(device)\n",
        "# for name, param in model.named_parameters(): print(name, param)\n",
        "# optim.zero_grad()\n",
        "# loss = F.mse_loss(out, y)\n",
        "# loss.backward()\n",
        "# optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5znfg9g-BOQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title lucidrains imagen stuff\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import inspect\n",
        "class Seq(nn.Sequential):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "        for layer in self:\n",
        "            params = inspect.signature(layer.forward).parameters.keys()\n",
        "            layer._fwdparams = ','.join(params)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        for layer in self:\n",
        "            args = [x]\n",
        "            if 'emb' in layer._fwdparams: args.append(emb)\n",
        "            if 'cond' in layer._fwdparams: args.append(cond)\n",
        "            x = layer(*args)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ChanRMSNorm(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.scale = dim ** 0.5\n",
        "        self.gamma = nn.Parameter(torch.ones(dim, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.normalize(x, dim = 1) * self.scale * self.gamma\n",
        "\n",
        "\n",
        "class Parallel(nn.Module):\n",
        "    def __init__(self, *fns):\n",
        "        super().__init__()\n",
        "        self.fns = nn.ModuleList(fns)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = [fn(x) for fn in self.fns]\n",
        "        return sum(outputs)\n",
        "\n",
        "class GlobalContext(nn.Module): # Global Context (GC) block\n",
        "    \"\"\" basically a superior form of squeeze-excitation that is attention-esque \"\"\"\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.to_k = nn.Conv2d(dim_in, 1, 1)\n",
        "        hidden_dim = max(3, dim_out // 2)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(dim_in, hidden_dim, 1), nn.SiLU(),\n",
        "            nn.Conv2d(hidden_dim, dim_out, 1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x): # [b, c, h, w]\n",
        "        context = self.to_k(x)\n",
        "        x, context = x.flatten(2), context.flatten(2) # [b, c, h*w] ,[b,1,h*w]\n",
        "        out = x @ context.softmax(dim=-1).transpose(1,2) # [b, c, 1]\n",
        "        out = out.unsqueeze(-1) # [b, c, 1, 1]\n",
        "        return self.net(out) # [b, dim_out, 1, 1]\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, d_head = 64,n_heads = 8, context_dim = None, scale = 8):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        d_model = d_head * n_heads\n",
        "        self.d_model, self.n_heads, self.d_head = d_model, n_heads, d_head\n",
        "        self.null_kv = nn.Parameter(torch.randn(2, 1, d_head))\n",
        "        self.qkv = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, d_model + 2*d_head, bias=False))\n",
        "        self.q_scale, self.k_scale = nn.Parameter(torch.ones(d_head)), nn.Parameter(torch.ones(d_head))\n",
        "\n",
        "        self.to_context = nn.Sequential(nn.LayerNorm(context_dim), nn.Linear(context_dim, 2*d_head)) if context_dim!=None else None\n",
        "        self.to_out = nn.Sequential(nn.Linear(d_model, dim, bias = False), nn.LayerNorm(dim),)\n",
        "\n",
        "    def forward(self, x, cond = None, mask = None, attn_bias = None): # [batch, T, d_model] = [b, hw, c], [batch, num_tok, context_dim]\n",
        "        batch, T, _ = x.shape#[0]\n",
        "        q, k, v = self.qkv(x).split([self.d_model, self.d_head, self.d_head], dim=-1) # [batch, T, d_model], 2*[batch, T, d_head]\n",
        "        q = q.reshape(batch, T, self.n_heads, -1).transpose(1,2) # [batch, n_heads, T, d_head]\n",
        "\n",
        "        nk, nv = self.null_kv.expand((batch,-1,-1,-1)).unbind(dim=1) # [2,1,d_head]->[batch,2,1,d_head]->[batch,1,d_head]\n",
        "        k, v = torch.cat((nk, k), dim=-2), torch.cat((nv, v), dim=-2) # [batch, 1+T, d_head]\n",
        "\n",
        "        if self.to_context!=None:\n",
        "            ck, cv = self.to_context(cond).chunk(2, dim = -1) # [batch, num_tok, d_head]\n",
        "            k, v = torch.cat((ck, k), dim=-2), torch.cat((cv, v), dim=-2) # [batch, num_tok+1+T, d_head]\n",
        "\n",
        "        q, k = F.normalize(q, dim=-1), F.normalize(k, dim=-1) # qk rmsnorm\n",
        "        q, k = q * self.q_scale, k * self.k_scale\n",
        "        k, v = k.unsqueeze(1), v.unsqueeze(1) # [batch, 1, num_tok+1+T, d_head]\n",
        "\n",
        "        sim = q @ k.transpose(-2,-1) * self.scale # [batch, n_heads, T, num_tok+1+T]\n",
        "        if attn_bias!=None: sim = sim + attn_bias # relative positional encoding (T5 style)\n",
        "        if mask!=None:\n",
        "            mask = F.pad(mask, (1, 0), value=True).unsqueeze(1).unsqeeze(2) # [b j] -> [b 1 1 j]\n",
        "            sim = sim.masked_fill(~mask, -torch.finfo(sim.dtype).max)\n",
        "        attn = sim.softmax(dim=-1) # attn = sim.softmax(dim=-1, dtype=torch.float32).to(sim.dtype)\n",
        "        out = (attn @ v).transpose(1,2).flatten(2) # [batch, n_heads, T, d_head] -> [batch, T, d_model]\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, dim, context_dim = None, d_head = 64,n_heads = 8, scale = 8):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        self.n_heads =n_heads\n",
        "        d_model = d_head *n_heads\n",
        "        if context_dim==None: context_dim = dim\n",
        "        self.to_q = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, d_model, bias=False))\n",
        "        self.to_kv = nn.Linear(context_dim, d_model * 2, bias=False)\n",
        "        # self.to_kv = nn.Sequential(nn.LayerNorm(context_dim), nn.Linear(context_dim, d_model * 2, bias=False))\n",
        "        self.null_kv = nn.Parameter(torch.randn(2, 1, 1, d_head))\n",
        "        self.q_scale, self.k_scale = nn.Parameter(torch.ones(d_head)), nn.Parameter(torch.ones(d_head))\n",
        "        self.to_out = nn.Sequential(nn.Linear(d_model, dim, bias = False), nn.LayerNorm(dim))\n",
        "\n",
        "    def forward(self, x, cond, mask = None): # [batch, T, dim]=[b, hw, c], [batch, num_tok, context_dim]\n",
        "        batch, T, _ = x.shape#[0]\n",
        "        _, num_tok, _ = cond.shape\n",
        "        q = self.to_q(x).reshape(batch, T, self.n_heads, -1).transpose(1,2) # [batch, n_heads, T, d_head]\n",
        "        k, v = self.to_kv(cond).chunk(2, dim = -1) # [batch, num_tok, d_model]\n",
        "        k = k.reshape(batch, num_tok, self.n_heads, -1).transpose(1,2) # [batch, n_heads, num_tok, d_head]\n",
        "        v = v.reshape(batch, num_tok, self.n_heads, -1).transpose(1,2) # [batch, n_heads, num_tok, d_head]\n",
        "\n",
        "        nk, nv = self.null_kv.expand((batch,-1,self.n_heads,-1,-1)).unbind(dim=1) # [2,1,1,d_head]->[batch,2,n_heads,1,d_head]->[batch,n_heads,1,d_head]\n",
        "        k, v = torch.cat((nk, k), dim=-2), torch.cat((nv, v), dim=-2) # [batch, n_heads, 1+num_tok, d_head]\n",
        "\n",
        "        q, k = F.normalize(q, dim=-1), F.normalize(k, dim=-1) # qk rmsnorm\n",
        "        q, k = q * self.q_scale, k * self.k_scale\n",
        "\n",
        "        sim = q @ k.transpose(-2,-1) * self.scale # [batch, n_heads, T, 1+num_tok]\n",
        "        if mask!=None:\n",
        "            mask = F.pad(mask, (1, 0), value=True).unsqueeze(1).unsqeeze(2) # [b j] -> [b 1 1 j]\n",
        "            sim = sim.masked_fill(~mask, -torch.finfo(sim.dtype).max)\n",
        "        attn = sim.softmax(dim=-1) # attn = sim.softmax(dim=-1, dtype=torch.float32).to(sim.dtype)\n",
        "        out = (attn @ v).transpose(1,2).flatten(2) # [batch, n_heads, T, d_head] -> [batch, T, d_model]\n",
        "        return self.to_out(out)\n",
        "\n",
        "class CrossEmbedLayer(nn.Module):\n",
        "    def __init__(self, dim_in, kernel_sizes, dim_out = None, stride = 2):\n",
        "        super().__init__()\n",
        "        assert all([*map(lambda t: (t % 2) == (stride % 2), kernel_sizes)])\n",
        "        if dim_out==None: dim_out = dim_in\n",
        "        kernel_sizes = sorted(kernel_sizes)\n",
        "        dim_scales = [int(dim_out / (2 ** i)) for i in range(1, len(kernel_sizes))] # [64, 32]\n",
        "        dim_scales = [*dim_scales, dim_out - sum(dim_scales)] # [64, 32, 32]\n",
        "        # 1/2 + 1/4 + 1/8 + ... + 1/2^num_kernels + 1/2^num_kernels of dim_out; smaller kernel allocated more channels\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(dim_in, dim_scale, kernel, stride=stride, padding=(kernel-stride)//2) for kernel, dim_scale in zip(kernel_sizes, dim_scales)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([conv(x) for conv in self.convs], dim = 1)\n",
        "\n",
        "\n",
        "def Upsample(in_ch, out_ch=None):\n",
        "    if out_ch==None: out_ch = in_ch\n",
        "    return nn.Sequential(nn.Interpolate(scale_factor = 2, mode = 'nearest'), nn.Conv2d(in_ch, out_ch, 3, padding=1))\n",
        "\n",
        "class PixelShuffleUpsample(nn.Module):\n",
        "    \"\"\"code shared by @MalumaDev at DALLE2-pytorch for addressing checkboard artifacts https://arxiv.org/ftp/arxiv/papers/1707/1707.02937.pdf\"\"\"\n",
        "    def __init__(self, in_ch, out_ch=None):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch = in_ch\n",
        "        self.net = nn.Sequential(nn.Conv2d(in_ch, out_ch * 4, 1), nn.SiLU(), nn.PixelShuffle(2)) # PixelShuffle: [b,c*r^2,h,w] -> [b,c,h*r,w*r] # upscale by upscale factor r # https://arxiv.org/pdf/1609.05158v2\n",
        "        self.init_conv_(self.net[0])\n",
        "\n",
        "    def init_conv_(self, conv):\n",
        "        o, i, h, w = conv.weight.shape\n",
        "        conv_weight = torch.empty(o//4, i, h, w)\n",
        "        nn.init.kaiming_uniform_(conv_weight)\n",
        "        conv_weight = conv_weight.repeat(4,1,1,1)\n",
        "        conv.weight.data.copy_(conv_weight)\n",
        "        nn.init.zeros_(conv.bias.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def Downsample(in_ch, out_ch=None): # https://arxiv.org/abs/2208.03641 shows this is the most optimal way to downsample, named SP-conv in the paper, but basically a pixel unshuffle\n",
        "    if out_ch==None: out_ch = in_ch\n",
        "    return nn.Sequential(nn.PixelUnshuffle(2), nn.Conv2d(in_ch * 4, out_ch, 1)) # PixelUnshuffle: [b,c,h*r,w*r] -> [b,c*r^2,h,w]\n",
        "\n",
        "\n",
        "\n",
        "def FeedForward(dim, mult = 2):\n",
        "    hidden_dim = int(dim * mult)\n",
        "    return nn.Sequential(\n",
        "        nn.LayerNorm(dim), nn.Linear(dim, hidden_dim, bias = False), nn.GELU(),\n",
        "        nn.LayerNorm(hidden_dim), nn.Linear(hidden_dim, dim, bias = False)\n",
        "    )\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, depth = 1,n_heads = 8, d_head = 32, ff_mult = 2, context_dim = None):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Attention(dim = dim,n_heads =n_heads, d_head = d_head, context_dim = context_dim),\n",
        "                FeedForward(dim = dim, mult = ff_mult)\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, cond = None):\n",
        "        bchw = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2) # [b, c, h, w] -> [b, h*w, c]\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x, cond) + x\n",
        "            x = ff(x) + x\n",
        "        x = x.transpose(1, 2).reshape(*bchw) # [b, h*w, c] -> [b, c, h, w]\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, dim_out, tok_dim = None, emb_dim = None,n_heads=None, d_head=None):\n",
        "        super().__init__()\n",
        "        if tok_dim != None: self.cross_attn = CrossAttention(dim = dim_out, context_dim = tok_dim, n_heads=n_heads, d_head=d_head) # CrossAttention LinearCrossAttention\n",
        "        else: self.cross_attn = None\n",
        "        self.block1 = nn.Sequential(ChanRMSNorm(dim), nn.SiLU(), nn.Conv2d(dim, dim_out, 3, padding = 1))\n",
        "        self.block2 = Seq(ChanRMSNorm(dim_out), scale_shift(dim_out, emb_dim) if emb_dim != None else nn.Identity(), nn.SiLU(), nn.Conv2d(dim_out, dim_out, 3, padding = 1))\n",
        "        self.gca = GlobalContext(dim_in = dim_out, dim_out = dim_out)\n",
        "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, emb = None, cond = None):\n",
        "        h = self.block1(x)\n",
        "        # print('ResnetBlock fwd', h.shape)\n",
        "        if self.cross_attn != None:\n",
        "            bhwc = h.shape\n",
        "            h = h.flatten(2).transpose(1, 2) # [b, h, w, c] -> [b, h*w, c]\n",
        "            h = self.cross_attn(h, cond=cond) + h\n",
        "            h = h.transpose(1, 2).reshape(*bhwc) # [b, h*w, c] -> [b, c, h, w]\n",
        "        h = self.block2(h, emb)\n",
        "        h = h * self.gca(h) # use_gca\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "\n",
        "class scale_shift(nn.Module): # FiLM\n",
        "    def __init__(self, x_dim, t_dim):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(nn.SiLU(), nn.Linear(t_dim, x_dim*2),)\n",
        "\n",
        "    def forward(self, x, emb = None): # [b,c,h,w], [b,emb_dim]\n",
        "        # print('scale_shift fwd', x.shape, emb.shape)\n",
        "        emb = self.time_mlp(emb)[..., None, None] # [b,t_dim] -> [b,2*x_dim,1,1]\n",
        "        scale, shift = emb.chunk(2, dim = 1) # [b,x_dim,1,1]\n",
        "        x = x * (scale + 1) + shift\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpM1jlvFvD9i",
        "outputId": "d08b7316-c345-4ebd-9595-1e95713310f3",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48127500\n",
            "torch.Size([1, 1, 16, 16])\n"
          ]
        }
      ],
      "source": [
        "# @title lucidrains imagen next\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, d_model, # 512 # base dimension of your u-net should ideally be no smaller than 128, as recommended by a professional DDPM trainer https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/\n",
        "        c_dim = 16, # cond vec dim\n",
        "        tok_dim = None, # token dim\n",
        "        out_dim = None,\n",
        "        dim_mults=(1, 2, 4, 8), # (1, 2, 3, 4)\n",
        "        in_ch = 3, out_ch = None,\n",
        "        layer_attns = True, # (False, True, True, True)\n",
        "        layer_cross_attns = True, # (False, True, True, True)\n",
        "        # num_resnet_blocks = 1, # 3\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        if out_ch == None: self.out_ch = in_ch\n",
        "        d_head = 64\n",
        "        n_heads = 8 # 8 # ideally at least 4 or 8\n",
        "\n",
        "        self.init_conv = CrossEmbedLayer(in_ch, dim_out = d_model, kernel_sizes = (3, 7, 15), stride = 1) #if init_cross_embed else nn.Conv2d(in_ch, d_model, 7, padding = 7 // 2)\n",
        "        dims = [d_model] + [d_model * m for m in dim_mults] # [128, 128, 256, 384, 512]\n",
        "        # dims = [d_model * m for m in dim_mults] # [128, 256, 384, 512]\n",
        "\n",
        "        # time conditioning\n",
        "        if tok_dim == None: tok_dim = d_model\n",
        "\n",
        "        # embedding time for log(snr) noise from continuous version\n",
        "        emb_dim = 16\n",
        "        emb_dim = d_model * 4 #* (2 if lowres_cond else 1)\n",
        "\n",
        "        # pos_emb = RotEmb(emb_dim, top=torch.pi, base=10000)\n",
        "        # self.time_hiddens = nn.Sequential(pos_emb, nn.Linear(emb_dim, emb_dim), nn.SiLU())\n",
        "\n",
        "        # self.time_cond = nn.Sequential(nn.Linear(emb_dim, emb_dim))\n",
        "        # num_time_tokens = 2\n",
        "        # self.time_tokens = nn.Sequential(nn.Linear(emb_dim, tok_dim * num_time_tokens), Rearrange('b (r d) -> b r d', r = num_time_tokens))\n",
        "        # # self.time_tokens = nn.Sequential(nn.Linear(emb_dim, tok_dim))\n",
        "\n",
        "        self.num_time_tokens = 2\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            RotEmb(emb_dim, top=torch.pi, base=10000),\n",
        "            nn.Linear(emb_dim, emb_dim), nn.SiLU(),\n",
        "            nn.Linear(emb_dim, emb_dim + self.num_time_tokens * tok_dim),\n",
        "        )\n",
        "        self.emb_dim, self.tok_dim = emb_dim, tok_dim\n",
        "\n",
        "\n",
        "        # self.cond_tokens = nn.Linear(c_dim, tok_dim)\n",
        "        # self.cond_cond = nn.Sequential(\n",
        "        #     nn.LayerNorm(tok_dim), nn.Linear(tok_dim, emb_dim), nn.SiLU(),\n",
        "        #     nn.Linear(emb_dim, emb_dim)\n",
        "        # )\n",
        "        self.cond_mlp = nn.Sequential(\n",
        "            nn.Linear(c_dim, tok_dim),\n",
        "            nn.LayerNorm(tok_dim), nn.Linear(tok_dim, emb_dim), nn.SiLU(),\n",
        "            nn.Linear(emb_dim, emb_dim + tok_dim)\n",
        "        )\n",
        "\n",
        "        self.norm_cond = nn.LayerNorm(tok_dim)\n",
        "\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "        num_layers = len(in_out)\n",
        "        # num_layers = len(dims)\n",
        "\n",
        "        self.downs = nn.ModuleList([])\n",
        "        # skip_connect_dims = [] # keep track of skip connection dimensions\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_layers - 1)\n",
        "            # print('down', dim_in, dim_out)\n",
        "\n",
        "            # skip_connect_dims.append(dim_in) # dim_out if memory_efficient\n",
        "            self.downs.append(nn.ModuleList([\n",
        "                # Downsample(dim_in, dim_out), # memory_efficient pre_downsample; self.downs all dim_out # Downsample cross_embed_downsample CrossEmbedLayer(dim_in, dim_out, kernel_sizes = (2, 4))\n",
        "                ResnetBlock(dim_in, dim_in, tok_dim = tok_dim, emb_dim = emb_dim, n_heads=n_heads, d_head=d_head),\n",
        "                nn.ModuleList([ResnetBlock(dim_in, dim_in, emb_dim = emb_dim) for _ in range(0)]),\n",
        "                TransformerBlock(dim = dim_in, depth = 1, ff_mult = 2, context_dim = tok_dim, n_heads=n_heads, d_head=d_head), # trans/ lintrans/ id\n",
        "                Downsample(dim_in, dim_out) if not is_last else Parallel(nn.Conv2d(dim_in, dim_out, 3, padding = 1), nn.Conv2d(dim_in, dim_out, 1)) # Downsample cross_embed_downsample CrossEmbedLayer(dim_in, dim_out, kernel_sizes = (2, 4))\n",
        "            ]))\n",
        "\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block = Seq(\n",
        "            ResnetBlock(mid_dim, mid_dim, tok_dim = tok_dim, emb_dim = emb_dim, n_heads=n_heads, d_head=d_head),\n",
        "            TransformerBlock(mid_dim, depth = 1, n_heads=n_heads, d_head=d_head), # True # whether to have a layer of attention at the bottleneck (can turn off for higher resolution in cascading DDPM, before bringing in efficient attention)\n",
        "            ResnetBlock(mid_dim, mid_dim, tok_dim = tok_dim, emb_dim = emb_dim, n_heads=n_heads, d_head=d_head),\n",
        "        )\n",
        "\n",
        "        self.ups = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
        "            is_last = ind == (num_layers - 1)\n",
        "            # skip_connect_dim = skip_connect_dims.pop()\n",
        "            # print('up', dim_in, dim_out, skip_connect_dim)\n",
        "            self.ups.append(nn.ModuleList([\n",
        "                ResnetBlock(dim_out + dim_in, dim_out, tok_dim = tok_dim, emb_dim = emb_dim, n_heads=n_heads, d_head=d_head),\n",
        "                nn.ModuleList([ResnetBlock(dim_out + dim_in, dim_out, emb_dim = emb_dim) for _ in range(0)]),\n",
        "                TransformerBlock(dim = dim_out, depth = 1, ff_mult = 2, context_dim = tok_dim, n_heads=n_heads, d_head=d_head), # trans/ lintrans/ id\n",
        "                PixelShuffleUpsample(dim_out, dim_in) if not is_last else nn.Identity() # PixelShuffleUpsample Upsample ; memory_efficient upscale at last too\n",
        "            ]))\n",
        "\n",
        "        self.final_res_block = ResnetBlock(d_model, d_model, emb_dim = emb_dim) #if final_resnet_block else None\n",
        "        self.final_conv = nn.Conv2d(d_model, self.out_ch, 3, padding = 3 // 2)\n",
        "        def zero_init_(m):\n",
        "            nn.init.zeros_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "        zero_init_(self.final_conv)\n",
        "\n",
        "    def forward(self, x, time, cond):\n",
        "        # cond_images = resize_image_to(cond_images, x.shape[-1], mode = 'nearest')\n",
        "        # x = torch.cat((cond_images, x), dim = 1)\n",
        "        x = self.init_conv(x)\n",
        "        # hiddens.append(x)\n",
        "\n",
        "        t, t_tok = self.time_mlp(time).split([self.emb_dim, self.num_time_tokens * self.tok_dim], dim=-1)\n",
        "        t_tok = t_tok.reshape(t_tok.shape[0], self.num_time_tokens, self.tok_dim)\n",
        "        cond_hid, c_tok = self.cond_mlp(cond).split([self.emb_dim, self.tok_dim], dim=-1)\n",
        "        # print('unet fwd', t_hid.shape, t_tok.shape, t.shape)\n",
        "\n",
        "        t = t + cond_hid # [batch, emb_dim]\n",
        "        c = torch.cat((t_tok, c_tok.unsqueeze(1)), dim=-2) # [b, num_toks, tok_dim]\n",
        "        c = self.norm_cond(c)\n",
        "\n",
        "        hiddens = []\n",
        "        # for pre_downsample, init_block, resnet_blocks, attn_block, post_downsample in self.downs:\n",
        "        for init_block, resnet_blocks, attn_block, post_downsample in self.downs:\n",
        "            # x = pre_downsample(x)\n",
        "            x = init_block(x, t, c)\n",
        "            for resnet_block in resnet_blocks:\n",
        "                x = resnet_block(x, t)\n",
        "                hiddens.append(x)\n",
        "            x = attn_block(x, c)\n",
        "            hiddens.append(x)\n",
        "            x = post_downsample(x)\n",
        "\n",
        "        # print('unet fwd', x.shape, t.shape, c.shape)\n",
        "        x = self.mid_block(x, t, c)\n",
        "\n",
        "        for init_block, resnet_blocks, attn_block, upsample in self.ups:\n",
        "            x = torch.cat((x, hiddens.pop() * 2**-.5), dim = 1)\n",
        "            x = init_block(x, t, c)\n",
        "            for resnet_block in resnet_blocks:\n",
        "                x = torch.cat((x, hiddens.pop() * 2**-.5), dim = 1)\n",
        "                x = resnet_block(x, t)\n",
        "            x = attn_block(x, c)\n",
        "            x = upsample(x)\n",
        "\n",
        "        # x = torch.cat((x, hiddens.pop()), dim = 1)\n",
        "        x = self.final_res_block(x, t)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "model = UNet(d_model=128, c_dim=10, in_ch=1, dim_mults = (1, 2, 3, 4)).to(device)\n",
        "batch = 1\n",
        "# x = torch.rand((batch, 3, 64, 64), device = device)\n",
        "x = torch.rand((batch, 1,16,16), device = device)\n",
        "t = torch.rand(batch, device = device)\n",
        "# img_cond = torch.rand((batch, 512, 64, 64), device = device)\n",
        "cond = torch.rand((batch, 10), device = device)\n",
        "out = model(x, t, cond)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "print(out.shape)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3) # 1e-3 3e-3\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QOiDHI7taUKF",
        "IQlJ4XVLrOSx"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}